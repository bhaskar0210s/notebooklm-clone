{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PDF Embeddings Generation\n",
        "\n",
        "This notebook reads a PDF file, extracts text, and generates embeddings using the embedding model configured in the environment variables.\n",
        "\n",
        "**Configuration:**\n",
        "- If `USE_OLLAMA=true`: Uses Ollama with `nomic-embed-text:latest`\n",
        "- Otherwise: Uses Google Generative AI with `models/embedding-001` (requires `GOOGLE_API_KEY`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run once if needed)\n",
        "# %pip install langchain-community langchain-ollama langchain-google-genai pypdf python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Configuration: USE_OLLAMA = False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "use_ollama = os.getenv(\"USE_OLLAMA\", \"false\").lower() == \"true\"\n",
        "print(f\"üìä Configuration: USE_OLLAMA = {use_ollama}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Initialized Vertex AI embeddings: gemini-embedding-001\n",
            "   Project: notebooklm-clone-483513\n",
            "   Location: asia-south1\n"
          ]
        }
      ],
      "source": [
        "# Initialize the embedding model based on environment configuration\n",
        "if use_ollama:\n",
        "    ollama_base_url = os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\")\n",
        "    embeddings = OllamaEmbeddings(\n",
        "        model=\"nomic-embed-text:latest\",\n",
        "        base_url=ollama_base_url\n",
        "    )\n",
        "    print(f\"‚úÖ Initialized Ollama embeddings: nomic-embed-text:latest\")\n",
        "    print(f\"   Base URL: {ollama_base_url}\")\n",
        "else:\n",
        "    project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\")\n",
        "    location = os.getenv(\"GOOGLE_CLOUD_LOCATION\", \"asia-south1\")\n",
        "    \n",
        "    if not project_id:\n",
        "        raise ValueError(\"GOOGLE_CLOUD_PROJECT_ID environment variable is required when not using Ollama\")\n",
        "\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(\n",
        "        model=\"models/gemini-embedding-001\",          # or \"models/text-embedding-004\" etc.\n",
        "        project=project_id,                # ‚Üê Required for Vertex AI\n",
        "        location=location,                       # Common location; check supported regions\n",
        "        vertexai=True,                                # This flag enables Vertex AI backend\n",
        "        output_dimensionality=768\n",
        "    )\n",
        "    print(f\"‚úÖ Initialized Vertex AI embeddings: gemini-embedding-001\")\n",
        "    print(f\"   Project: {project_id}\")\n",
        "    print(f\"   Location: {location}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Loading PDF from: backend/src/upload_graph/Sample-Accounting-Income-Statement.pdf\n",
            "‚úÖ Loaded 7 document(s) from PDF\n",
            "\n",
            "üìã First document metadata:\n",
            "   Page: 0\n",
            "   Source: backend/src/upload_graph/Sample-Accounting-Income-Statement.pdf\n",
            "\n",
            "üìù First document preview (first 200 chars):\n",
            "   Understanding Basic Financial Statements\n",
            "During the accounting cycle, the accounting system is used to track, organize and record the financial\n",
            "transactions of an organization. At the close of each pe...\n"
          ]
        }
      ],
      "source": [
        "# Load the PDF file\n",
        "pdf_path = Path(\"backend/src/upload_graph/Sample-Accounting-Income-Statement.pdf\")\n",
        "\n",
        "if not pdf_path.exists():\n",
        "    raise FileNotFoundError(f\"PDF file not found at: {pdf_path}\")\n",
        "\n",
        "print(f\"üìÑ Loading PDF from: {pdf_path}\")\n",
        "\n",
        "# Load PDF using LangChain's PyPDFLoader\n",
        "loader = PyPDFLoader(str(pdf_path))\n",
        "docs = loader.load()\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(docs)} document(s) from PDF\")\n",
        "\n",
        "# Display first document metadata\n",
        "if docs:\n",
        "    print(f\"\\nüìã First document metadata:\")\n",
        "    print(f\"   Page: {docs[0].metadata.get('page', 'N/A')}\")\n",
        "    print(f\"   Source: {docs[0].metadata.get('source', 'N/A')}\")\n",
        "    print(f\"\\nüìù First document preview (first 200 chars):\")\n",
        "    print(f\"   {docs[0].page_content[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Extracted 7 text chunk(s)\n",
            "   Total characters: 10376\n",
            "\n",
            "   Chunk 1: 3435 characters\n",
            "   Preview: Understanding Basic Financial Statements\n",
            "During the accounting cycle, the accounting system is used ...\n",
            "\n",
            "   Chunk 2: 910 characters\n",
            "   Preview: XYZ COMPANY LIMITED\n",
            "BALANCE SHEET\n",
            "AS AT\n",
            "JUNE 30, 2002\n",
            "UNAUDITED - See \"Notice to Reader\"\n",
            "2002 2001\n",
            "A...\n",
            "\n",
            "   Chunk 3: 1138 characters\n",
            "   Preview: XYZ COMPANY LIMITED\n",
            "STATEMENT OF INCOME AND RETAINED EARNINGS\n",
            "FOR THE YEAR ENDED\n",
            "JUNE 30, 2002\n",
            "UNAUD...\n"
          ]
        }
      ],
      "source": [
        "# Extract all text from documents\n",
        "all_texts = [doc.page_content for doc in docs]\n",
        "print(f\"üìù Extracted {len(all_texts)} text chunk(s)\")\n",
        "print(f\"   Total characters: {sum(len(text) for text in all_texts)}\")\n",
        "\n",
        "# Display text statistics\n",
        "for i, text in enumerate(all_texts[:3], 1):  # Show first 3 chunks\n",
        "    print(f\"\\n   Chunk {i}: {len(text)} characters\")\n",
        "    print(f\"   Preview: {text[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Generating embeddings...\n",
            "   Processing batch 1/2 (5 texts)...\n",
            "   ‚úÖ Batch 1 completed\n",
            "   Processing batch 2/2 (2 texts)...\n",
            "   ‚úÖ Batch 2 completed\n",
            "\n",
            "‚úÖ Generated 7 embeddings\n",
            "   Embedding dimension: 768\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings for all text chunks\n",
        "print(\"üîÑ Generating embeddings...\")\n",
        "\n",
        "# Generate embeddings in batches to avoid rate limits\n",
        "batch_size = 5\n",
        "all_embeddings = []\n",
        "\n",
        "for i in range(0, len(all_texts), batch_size):\n",
        "    batch = all_texts[i:i + batch_size]\n",
        "    batch_num = (i // batch_size) + 1\n",
        "    total_batches = (len(all_texts) + batch_size - 1) // batch_size\n",
        "    \n",
        "    print(f\"   Processing batch {batch_num}/{total_batches} ({len(batch)} texts)...\")\n",
        "    \n",
        "    try:\n",
        "        batch_embeddings = embeddings.embed_documents(batch)\n",
        "        all_embeddings.extend(batch_embeddings)\n",
        "        print(f\"   ‚úÖ Batch {batch_num} completed\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error in batch {batch_num}: {e}\")\n",
        "        raise\n",
        "\n",
        "print(f\"\\n‚úÖ Generated {len(all_embeddings)} embeddings\")\n",
        "print(f\"   Embedding dimension: {len(all_embeddings[0]) if all_embeddings else 'N/A'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Embedding Statistics:\n",
            "   Shape: (7, 3072)\n",
            "   Mean: -0.000133\n",
            "   Std: 0.018042\n",
            "   Min: -0.235695\n",
            "   Max: 0.252917\n",
            "\n",
            "üî¢ First embedding preview (first 10 dimensions):\n",
            "   [-0.00233125570230186, 0.011832311749458313, 0.03495323657989502, -0.0471910797059536, 0.0049485107883811, 0.00774120120331645, 0.014832611195743084, 0.011454415507614613, -0.0286474097520113, 0.004035902675241232]\n"
          ]
        }
      ],
      "source": [
        "# Display embedding statistics\n",
        "import numpy as np\n",
        "\n",
        "if all_embeddings:\n",
        "    embeddings_array = np.array(all_embeddings)\n",
        "    \n",
        "    print(\"üìä Embedding Statistics:\")\n",
        "    print(f\"   Shape: {embeddings_array.shape}\")\n",
        "    print(f\"   Mean: {embeddings_array.mean():.6f}\")\n",
        "    print(f\"   Std: {embeddings_array.std():.6f}\")\n",
        "    print(f\"   Min: {embeddings_array.min():.6f}\")\n",
        "    print(f\"   Max: {embeddings_array.max():.6f}\")\n",
        "    \n",
        "    # Show first embedding (first 10 dimensions)\n",
        "    print(f\"\\nüî¢ First embedding preview (first 10 dimensions):\")\n",
        "    print(f\"   {all_embeddings[0][:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Testing query embedding: 'What is the total revenue?'\n",
            "‚úÖ Query embedding generated\n",
            "   Dimension: 3072\n",
            "   First 10 dimensions: [-0.0202526543289423, 0.0029630553908646107, 0.009256268851459026, -0.06388071179389954, 0.016612660139799118, 0.0016189336311072111, -0.0022575261536985636, -0.01491749007254839, -0.03048672527074814, 0.012214137241244316]\n"
          ]
        }
      ],
      "source": [
        "# Optional: Test embedding a query to verify the model works for retrieval\n",
        "test_query = \"What is the total revenue?\"\n",
        "\n",
        "print(f\"üîç Testing query embedding: '{test_query}'\")\n",
        "\n",
        "try:\n",
        "    query_embedding = embeddings.embed_query(test_query)\n",
        "    print(f\"‚úÖ Query embedding generated\")\n",
        "    print(f\"   Dimension: {len(query_embedding)}\")\n",
        "    print(f\"   First 10 dimensions: {query_embedding[:10]}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error generating query embedding: {e}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
