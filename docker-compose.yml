services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: notebooklm-backend
    ports:
      - "2024:2024"
    environment:
      - PORT=2024
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY}
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    volumes:
      # Mount source code for development (optional - remove for production)
      - ./backend/src:/app/src
    networks:
      - notebooklm-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2024/health", "||", "exit", "1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: notebooklm-frontend
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_LANGGRAPH_API_URL=http://backend:2024
    depends_on:
      - backend
    networks:
      - notebooklm-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health", "||", "exit", "1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  notebooklm-network:
    driver: bridge
