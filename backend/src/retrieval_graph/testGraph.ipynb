{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Retrieval Graph\n",
        "\n",
        "This notebook tests the retrieval graph by connecting to the LangGraph server.\n",
        "\n",
        "**Prerequisites:**\n",
        "1. Start the LangGraph dev server: `cd backend && npm run dev`\n",
        "2. Make sure the server is running at `http://localhost:2024`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run once)\n",
        "# %pip install langgraph-sdk\n",
        "# Ollama is running locally for this test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Connected to LangGraph server\n"
          ]
        }
      ],
      "source": [
        "from langgraph_sdk import get_client\n",
        "\n",
        "# Connect to the local LangGraph server\n",
        "# Make sure you've started it with: cd backend && npm run dev\n",
        "client = get_client(url=\"http://localhost:2024\")\n",
        "\n",
        "print(\"âœ… Connected to LangGraph server\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Created thread: 9e03dda6-8e30-4253-8355-114681cc287e\n"
          ]
        }
      ],
      "source": [
        "# Create a new thread (conversation session)\n",
        "thread = await client.threads.create()\n",
        "print(f\"âœ… Created thread: {thread['thread_id']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What is the capital of France?\n",
            "\n",
            "âœ… Graph execution completed!\n",
            "\n",
            "Result: {'run_id': '16d9e848-2c71-48de-bef1-7be976b71c18', 'thread_id': '9e03dda6-8e30-4253-8355-114681cc287e', 'assistant_id': '571ade52-f5cd-582a-89d9-d79dc861a8ba', 'metadata': {'created_by': 'system', 'graph_id': 'retrieval_graph', 'assistant_id': '571ade52-f5cd-582a-89d9-d79dc861a8ba'}, 'status': 'pending', 'kwargs': {'input': {'query': 'What is the capital of France?'}, 'config': {'configurable': {'user-agent': 'langgraph-sdk-py/0.2.14', 'run_id': '16d9e848-2c71-48de-bef1-7be976b71c18', 'thread_id': '9e03dda6-8e30-4253-8355-114681cc287e', 'graph_id': 'retrieval_graph', 'assistant_id': '571ade52-f5cd-582a-89d9-d79dc861a8ba'}, 'metadata': {'created_by': 'system', 'graph_id': 'retrieval_graph', 'assistant_id': '571ade52-f5cd-582a-89d9-d79dc861a8ba'}}, 'context': {}, 'stream_mode': ['values'], 'temporary': False, 'subgraphs': False, 'resumable': False}, 'multitask_strategy': 'reject', 'created_at': '2026-01-27T05:38:44.943Z', 'updated_at': '2026-01-27T05:38:44.943Z'}\n",
            "\n",
            "Status: pending\n"
          ]
        }
      ],
      "source": [
        "## Test 1: Simple Query (Non-streaming)\n",
        "\n",
        "# Test with a simple query\n",
        "test_query = \"What is the capital of France?\"\n",
        "\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "\n",
        "result = await client.runs.create(\n",
        "    thread_id=thread['thread_id'],\n",
        "    assistant_id=\"retrieval_graph\",\n",
        "    input={\"query\": test_query},\n",
        "    \n",
        ")\n",
        "\n",
        "print(\"âœ… Graph execution completed!\")\n",
        "print(f\"\\nResult: {result}\")\n",
        "print(f\"\\nStatus: {result.get('status', 'unknown')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Messages in thread:\n",
            "\n",
            "- human: What is the capital of France?\n",
            "\n",
            "- ai: The capital of France is **Paris**.\n"
          ]
        }
      ],
      "source": [
        "# Get the thread state which contains messages\n",
        "thread_state = await client.threads.get(thread_id=thread['thread_id'])\n",
        "\n",
        "# Access messages from the thread's state\n",
        "messages = thread_state.get('values', {}).get('messages', [])\n",
        "\n",
        "print(\"Messages in thread:\")\n",
        "for msg in messages:\n",
        "    msg_type = msg.get('type') if isinstance(msg, dict) else getattr(msg, 'type', 'unknown')\n",
        "    msg_content = msg.get('content') if isinstance(msg, dict) else getattr(msg, 'content', '')\n",
        "    print(f\"\\n- {msg_type}: {msg_content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: Add 600 + 3000\n",
            "\n",
            "âœ… Canceled\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "# Test with a simple query\n",
        "test_query = \"Add 600 + 3000\"\n",
        "\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "\n",
        "result = await client.runs.create(\n",
        "    thread_id=thread['thread_id'],\n",
        "    assistant_id=\"retrieval_graph\",\n",
        "    input={\"query\": test_query},\n",
        "    # config={\n",
        "    #     \"configurable\": {\n",
        "    #         \"queryModel\": \"ollama/llama3.2:1b\"\n",
        "    #     }\n",
        "    # }\n",
        ")\n",
        "\n",
        "# cancel the run after 100ms\n",
        "run_id = result.get('run_id') if isinstance(result, dict) else getattr(result, 'run_id', None)\n",
        "thread_id = thread['thread_id']\n",
        "if run_id:\n",
        "    await asyncio.sleep(0.1)\n",
        "    \n",
        "    target_run_id = run_id or globals().get('current_run_id')\n",
        "    if not target_run_id:\n",
        "        print(\"âŒ No run ID found.\")\n",
        "    else:\n",
        "        # Cancel the run\n",
        "        await client.runs.cancel(thread_id=thread_id, run_id=target_run_id)\n",
        "        print(f\"âœ… Canceled\")\n",
        "\n",
        "\n",
        "# Get the thread state which contains messages\n",
        "thread_state = await client.threads.get(thread_id=thread['thread_id'])\n",
        "\n",
        "# Access messages from the thread's state\n",
        "messages = thread_state.get('values', {}).get('messages', [])\n",
        "\n",
        "if messages:\n",
        "    # Get the latest message (last in the list)\n",
        "    latest = messages[-1]\n",
        "    latest_content = latest.get('content') if isinstance(latest, dict) else getattr(latest, 'content', None)\n",
        "    if latest_content:\n",
        "        print(f\"Response: {latest_content}\")\n",
        "print(thread_state.get('values', {}).get('messages', []))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# Get the thread state which contains messages\n",
        "thread_state = await client.threads.get(thread_id=thread['thread_id'])\n",
        "\n",
        "# Access messages from the thread's state\n",
        "messages = thread_state.get('values', {}).get('messages', [])\n",
        "\n",
        "if messages:\n",
        "    # Get the latest message (last in the list)\n",
        "    latest = messages[-1]\n",
        "    latest_content = latest.get('content') if isinstance(latest, dict) else getattr(latest, 'content', None)\n",
        "    if latest_content:\n",
        "        print(f\"Response: {latest_content}\")\n",
        "print(thread_state.get('values', {}).get('messages', []))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What is the capital of France?\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'thread' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m test_query = \u001b[33m\"\u001b[39m\u001b[33mWhat is the capital of France?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m client.runs.create(\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     thread_id=\u001b[43mthread\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     10\u001b[39m     assistant_id=\u001b[33m\"\u001b[39m\u001b[33mretrieval_graph\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[38;5;28minput\u001b[39m={\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: test_query},\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Graph execution completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'thread' is not defined"
          ]
        }
      ],
      "source": [
        "## Test 1: Simple Query (Non-streaming)\n",
        "\n",
        "# Test with a simple query\n",
        "test_query = \"What is the capital of France?\"\n",
        "\n",
        "print(f\"Query: {test_query}\\n\")\n",
        "\n",
        "result = await client.runs.create(\n",
        "    thread_id=thread['thread_id'],\n",
        "    assistant_id=\"retrieval_graph\",\n",
        "    input={\"query\": test_query},\n",
        "    \n",
        ")\n",
        "\n",
        "print(\"âœ… Graph execution completed!\")\n",
        "print(f\"\\nResult: {result}\")\n",
        "print(f\"\\nStatus: {result.get('status', 'unknown')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Messages in thread:\n"
          ]
        }
      ],
      "source": [
        "# Get the thread state which contains messages\n",
        "thread_state = await client.threads.get(thread_id=thread['thread_id'])\n",
        "\n",
        "# Access messages from the thread's state\n",
        "messages = thread_state.get('values', {}).get('messages', [])\n",
        "\n",
        "print(\"Messages in thread:\")\n",
        "for msg in messages:\n",
        "    msg_type = msg.get('type') if isinstance(msg, dict) else getattr(msg, 'type', 'unknown')\n",
        "    msg_content = msg.get('content') if isinstance(msg, dict) else getattr(msg, 'content', '')\n",
        "    print(f\"\\n- {msg_type}: {msg_content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: Tell me a joke\n",
            "\n",
            "Streaming response:\n",
            "ðŸ“¦ Chunk: StreamPart(event='metadata', data={'run_id': '1be2de3b-b35a-42e9-a35b-1dedeb429de7', 'attempt': 1})\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/complete', data=[{'content': 'What is the capital of France?', 'additional_kwargs': {}, 'response_metadata': {}, 'id': 'c710cca0-6195-4f10-9bcf-1e81675351a4', 'type': 'human'}, {'content': 'The capital of France is Paris.', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.2:1b', 'created_at': '2025-12-29T09:30:09.625641Z', 'done': True, 'done_reason': 'stop', 'total_duration': 822236500, 'load_duration': 83998500, 'prompt_eval_count': 32, 'prompt_eval_duration': 595260875, 'eval_count': 8, 'eval_duration': 87249834}, 'tool_call_chunks': [], 'id': 'run-019b6971-9020-7224-b84e-95533abaec8c', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/metadata', data={'run-019b6971-efb5-7224-b84e-c1f387666309': {'metadata': {'created_by': 'system', 'graph_id': 'retrieval_graph', 'assistant_id': '571ade52-f5cd-582a-89d9-d79dc861a8ba', 'run_attempt': 1, 'langgraph_version': '1.0.7', 'langgraph_plan': 'developer', 'langgraph_host': 'self-hosted', 'langgraph_api_url': 'http://localhost:2024', 'queryModel': 'ollama/llama3.2:1b', 'user-agent': 'langgraph-sdk-py/0.2.14', 'run_id': '1be2de3b-b35a-42e9-a35b-1dedeb429de7', 'thread_id': 'f4d5c8cb-309f-4535-8bbd-31b6ccade6bb', 'langgraph_step': 4, 'langgraph_node': 'directAnswer', 'langgraph_triggers': ['branch:to:directAnswer'], 'langgraph_path': ['__pregel_pull', 'directAnswer'], 'langgraph_checkpoint_ns': 'directAnswer:1ec3b6ae-db38-56bd-a624-de9a9702f30b', '__pregel_task_id': '1ec3b6ae-db38-56bd-a624-de9a9702f30b', 'checkpoint_ns': 'directAnswer:1ec3b6ae-db38-56bd-a624-de9a9702f30b', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.7}}})\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A', 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'tool_call_chunks': [], 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian,', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pav', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and Sch', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and Schr', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶d', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\"', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\n', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies,', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell,', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s here', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s here or', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s here or not', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/partial', data=[{'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"', 'additional_kwargs': {}, 'response_metadata': {}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "ðŸ”„ Update: StreamPart(event='updates', data={'directAnswer': {'messages': [{'content': 'Tell me a joke', 'additional_kwargs': {}, 'response_metadata': {}, 'id': 'run-019b6971-efb4-7224-b84e-bfdcebdc3e2e', 'type': 'human'}, {'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.2:1b', 'created_at': '2025-12-29T09:30:34.479145Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1207840792, 'load_duration': 78840334, 'prompt_eval_count': 53, 'prompt_eval_duration': 87313292, 'eval_count': 55, 'eval_duration': 652198127}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'usage_metadata': {'input_tokens': 53, 'output_tokens': 55, 'total_tokens': 108, 'input_token_details': {}, 'output_token_details': {}}, 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}]}})\n",
            "ðŸ“¦ Chunk: StreamPart(event='messages/complete', data=[{'content': 'Tell me a joke', 'additional_kwargs': {}, 'response_metadata': {}, 'id': 'run-019b6971-efb4-7224-b84e-bfdcebdc3e2e', 'type': 'human'}, {'content': 'A man walks into a library and asks the librarian, \"Do you have any books on Pavlov\\'s dogs and SchrÃ¶dinger\\'s cat?\" \\n\\nThe librarian replies, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"', 'additional_kwargs': {}, 'response_metadata': {'model': 'llama3.2:1b', 'created_at': '2025-12-29T09:30:34.479145Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1207840792, 'load_duration': 78840334, 'prompt_eval_count': 53, 'prompt_eval_duration': 87313292, 'eval_count': 55, 'eval_duration': 652198127}, 'tool_call_chunks': [], 'id': 'run-019b6971-efb5-7224-b84e-c1f387666309', 'usage_metadata': {'input_tokens': 53, 'output_tokens': 55, 'total_tokens': 108, 'input_token_details': {}, 'output_token_details': {}}, 'tool_calls': [], 'invalid_tool_calls': [], 'type': 'ai'}])\n",
            "\n",
            "âœ… Streaming completed!\n"
          ]
        }
      ],
      "source": [
        "## Test 2: Streaming Response\n",
        "\n",
        "# Test with streaming\n",
        "test_query_2 = \"Tell me a joke\"\n",
        "\n",
        "print(f\"Query: {test_query_2}\\n\")\n",
        "print(\"Streaming response:\")\n",
        "\n",
        "# Remove 'await' here - stream() returns an async generator directly\n",
        "stream = client.runs.stream(\n",
        "    thread_id=thread['thread_id'],\n",
        "    assistant_id=\"retrieval_graph\",\n",
        "    input={\"query\": test_query_2},\n",
        "    stream_mode=[\"messages\", \"updates\"],\n",
        "    config={\n",
        "        \"configurable\": {\n",
        "            \"queryModel\": \"ollama/llama3.2:1b\"\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "async for chunk in stream:\n",
        "    chunk_event = chunk.get('event') if isinstance(chunk, dict) else getattr(chunk, 'event', None)\n",
        "    if chunk_event == 'messages':\n",
        "        chunk_data = chunk.get('data') if isinstance(chunk, dict) else getattr(chunk, 'data', None)\n",
        "        if chunk_data:\n",
        "            for msg in chunk_data:\n",
        "                msg_content = msg.get('content') if isinstance(msg, dict) else getattr(msg, 'content', None)\n",
        "                if msg_content:\n",
        "                    print(f\"ðŸ“¨ {msg_content}\")\n",
        "    elif chunk_event == 'updates':\n",
        "        print(f\"ðŸ”„ Update: {chunk}\")\n",
        "    else:\n",
        "        print(f\"ðŸ“¦ Chunk: {chunk}\")\n",
        "\n",
        "print(\"\\nâœ… Streaming completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "Query 1: What is 2 + 2?\n",
            "==================================================\n",
            "Response: 2 + 2 = 4.\n",
            "\n",
            "==================================================\n",
            "Query 2: What about 3 + 3?\n",
            "==================================================\n",
            "Response: 3 + 3 = 6.\n",
            "\n",
            "==================================================\n",
            "Query 3: Can you add those two answers together?\n",
            "==================================================\n",
            "Response: Let's add the two results:\n",
            "\n",
            "4 (from 2 + 2) + 6 (from 3 + 3) = 10.\n",
            "\n",
            "So, the total is 10.\n",
            "\n",
            "âœ… All queries completed!\n"
          ]
        }
      ],
      "source": [
        "## Test 3: Multiple Queries in Same Thread\n",
        "\n",
        "thread = await client.threads.create()\n",
        "# Test multiple queries in the same thread (conversation history)\n",
        "queries = [\n",
        "    \"What is 2 + 2?\",\n",
        "    \"What about 3 + 3?\",\n",
        "    \"Can you add those two answers together?\"\n",
        "]\n",
        "\n",
        "import asyncio\n",
        "\n",
        "for i, query in enumerate(queries, 1):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Query {i}: {query}\")\n",
        "    print('='*50)\n",
        "    \n",
        "    result = await client.runs.create(\n",
        "        thread_id=thread['thread_id'],\n",
        "        assistant_id=\"retrieval_graph\",\n",
        "        input={\"query\": query},\n",
        "        config={\n",
        "            \"configurable\": {\n",
        "                # \"queryModel\": \"ollama/qwen3:4b\"\n",
        "                # \"queryModel\": \"ollama/llama3.2:1b\"\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Wait for the run to complete by polling its status\n",
        "    run_id = result.get('run_id') if isinstance(result, dict) else getattr(result, 'run_id', None)\n",
        "    if run_id:\n",
        "        while True:\n",
        "            run_status = await client.runs.get(\n",
        "                thread_id=thread['thread_id'],\n",
        "                run_id=run_id\n",
        "            )\n",
        "            status = run_status.get('status') if isinstance(run_status, dict) else getattr(run_status, 'status', None)\n",
        "            if status in ['success', 'error', 'cancelled']:\n",
        "                break\n",
        "            await asyncio.sleep(0.5)  # Poll every 500ms\n",
        "    \n",
        "    # Get the thread state which contains messages\n",
        "    thread_state = await client.threads.get(thread_id=thread['thread_id'])\n",
        "    \n",
        "    # Access messages from the thread's state\n",
        "    messages = thread_state.get('values', {}).get('messages', [])\n",
        "    \n",
        "    if messages:\n",
        "        # Get the latest message (last in the list)\n",
        "        latest = messages[-1]\n",
        "        latest_content = latest.get('content') if isinstance(latest, dict) else getattr(latest, 'content', None)\n",
        "        if latest_content:\n",
        "            print(f\"Response: {latest_content}\")\n",
        "\n",
        "print(\"\\nâœ… All queries completed!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
